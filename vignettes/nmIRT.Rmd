---
title: "nmIRT"
author: "Rikard Nordgren"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{nmIRT}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

nmIRT as an R package for generation and diagnostics of IRT NONMEM models.

## Scales

A scale object is a representation in R of a certain scale. It is a collection of items that each has an item number, a type (currently ordered categorical and binmary are supported) and a set of levels. A scale object can be created in multiple ways.

### Using a built in scale

```{r, fig.show='hold'}
library(nmIRT)
scale <- predefined_scale("MDS-UPDRS")
```
To find out which scales are available
```{r, fig.show='hold'}
list_predefined_scales()
```

### Getting an overview of a scale
A table of all items of a scale can be generated
```{r}
scale_overview(scale)
```

There is also the option of getting just the item numbers available or all that are of binary type
```{r, fig.show='hold'}
all_items(scale)
binary_items(scale)
```


### Generating a scale from a data.frame
```{r, fig.show='hold'}
df <- data.frame(ID=c(1,1,1,2,2,2), ITEM=c(1,2,3,1,2,3), DV=c(0,2,4,1,2,1))

scale <- scale_from_dataset(df)
```

By default the item column is called ITEM and the dv column is called DV, but this can be changed with options
```{r, eval=FALSE, fig.show='hold'}
scale <- scale_from_dataset(df, item='ITEM', dv='DV')
```

Note that if the dataset has an MDV column it will be used to filter out missing DVs.

### Generating a scale from a dataset file
```{r, eval=FALSE, fig.show='hold'}
scale <- scale_from_dataset("mydata.csv")
```

### Load scale from a scale definition file
More information on how to work with scale definition files can be found in [a separate vignette](scale_defintion_files.html)

```{r, eval=FALSE, fig.show='hold'}
scale <- load_scale("myscale.yaml")
```

### Save a scale to a scale definition file
```{r, eval=FALSE, fig.show='hold'}
scale <- save_scale(scale, "myscale.yaml")
```


### Check a dataset against a scale
```{r, eval=FALSE}
data_check(dataset, scale)
```
This function will check if there are items or levels missing from the dataset that are present in the scale or vice versa.


## Modifying a scale

### Create subscales using categories
Items of a scale can belong to zero or more categories. These categories simplifies the creation of subscales. The following example will create a subscale of the items belonging to the "motor" category.

```{r, fig.show='hold', eval=FALSE}
subscale <- select_categories(scale, c("motor"))
```

It is also possible to simply list all items in a certain combination of categories.

```{r}
items_in_categories(predefined_scale("MDS-UPDRS"), c("motor", "tremor"))
```

### Remove items from a scale
```{r, fig.show='hold', eval=FALSE}
new_scale <- remove_items(scale, 1:14)
```

### Consolidate levels
A basic mechanism for consolidating items of a scale is available. This will merge items together. If we for example have a very few observations for level 4 in item number 14 and we would like to consolidate level 4 into level 3. The third arguments is a vector of levels that we wish to merge together. Levels must be at one end of the available levels.

```{r, fig.show='hold', eval=FALSE}
new_scale <- consolidate_levels(scale, 14, c(3, 4))
```

## Creating a model object from a scale
```{r, fig.show='hold'}
model <- irt_model(scale)
```

### Using a base scale for a model
A model can have one scale and one base_scale. By default they are the same, but in some cases it is of benefit to use the base scale. A base scale is the scale from which the ordinary scale was derived. Let us say that you are using a predefined scale, but are modifing it in some way, for example by removing items. Then the base scale would still be the full scale allowing the model generation procedure to put placeholders for the missing items.
```{r}
base_scale <- predefined_scale("MDS-UPDRS")
scale <- remove_items(base_scale, 14) # This will remove item number 14
model <- irt_model(scale, base_scale)
```
The scale and base scales of a model can be replaced at any point
```{r, eval=FALSE}
model <- set_scale(model, new_scale, new_basescale)
```


### Attach a dataset to a model
```{r, eval=FALSE}
model <- add_dataset(model, "my.dta")
```

### Generate the NONMEM code from a model object
```{r, fig.show='hold', eval=FALSE}
scale <- scale_from_dataset(df)
model <- irt_model(scale)
print_model(model)
```

### Write the NONMEM code to a file
```{r, eval=FALSE}
save_model(model, "run1.mod")
```

## Make changes to a model

### Add a simulation task
```{r, eval=FALSE}
model <- add_simulation(model, nsim=50)
```

### Consolidate levels by fixing parameters
It is possible to consolidate levels in the upper end of the level range by fixing the corresponding DIF parameter to a high value and keeping the level in the model. The benefit of this is to facilitate using different datasets for the same model by only changing the initial estimates. This is done on the model object:
```{r, eval=FALSE}
model <- consolidate_levels_in_model(model, 23, c(3, 4))
```

This will set the probability of level 4 to 0 by fixing DIF4 to a high value. The item number can be a list of items to consolidate the same levels for.

### Set the run number
```{r, eval=FALSE}
model <- set_run_number(model, 28)
```

This will set the run number to 28, which will add this number to the names of all table files generated by the model. If a number was not set the default of 1 would be used.


## Working with parameters

### Getting parameter names

```{r}
item_parameter_names(scale, 1)
```

### Initial estimates
There are multiple ways of setting the initial estimates for the item parameters in an irt model. This is the order of priority of how the initial estimates are determined:

1. User defined value from ```initial_estimates_item_parameters```
2. 50 if the parameter was consolidated
3. Taken from the published model in the scale
4. A fall back value of:
       Binary: DIS=1, DIF=0.1, GUE=0.01
       Ordered categorical: DIS=1, DIFn=$-3 + \frac{6n}{n_{cats}}$

### Providing user defined initial estimates
The most straight forward way of setting some initial estimates is to use the function ```initial_estimates_item_parameters```.

For example
```{r, eval=FALSE}
model <- initial_estimates_item_parameters(model, 1:13, c("DIF2", "DIF3", "DIF4"), 0.1)
```
will set all the initial estimates for the DIF2, DIF3 and DIF4 parameters for items 1 through 13 to 0.1

A vector of initial estimates can also be supplied and these will then be broadcast to all each parameter. For example
```{r, eval=FALSE}
model <- initial_estimates_item_parameters(model, 1:3, c("DIF2", "DIF3"), c(0.1, 0.2))
```
will set the initial estimates for DIF2 and DIF3 for items 1, 2 and 3 to 0.1 for the DIF2:s and 0.2 for the DIF3:s

### Fixing parameters

It is possible to fix certain item parameters of a model.

For example
```{r, eval=FALSE}
model <- fix_item_parameters(model, items_in_categories(scale, "motor"), item_parameter_names(scale, 1)
```
will fix all parameters in the motor category


## Diagnostic plots

The diagnostic plots can be created after an IRT model has been run. They will take as input data frames containing output from NONMEM.

### Item characteristic curves

To generate a set of item characteristic curves

```{r, eval=FALSE}
scale <- predefined_scale("MDS-UPDRS")
df <- read.table("item_parameters_tab1", skip=1, header=T, sep=",")
plots <- icc_plots(df, scale, items_per_page=6)
print(plots)
```

### Mirror plot

The mirror plot gives an overview of the frequencies of levels in the dataset and compares it to frequencies in simulations.

```{r, eval=FALSE}
scale <- predefined_scale("MDS-UPDRS")
origdata <- read.table("mydata.dta")
simdata <- read.table("simulation_tab1", skip=1, header=T, sep=",")
plots <- mirror_plots(origdata, scale, simdata, nrow=4, ncol=5)
print(plots)
```

### Correlation plot

The correlation plots give a heatmap of correlations between residuals.

```{r, eval=FALSE}
psi.estimates <- read.table("psi_tab1", skip=1, header=T)
plot <- correlation_plot(psi.estimates)
print(plot)
```